{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a42f64e-0164-4028-b522-bf53114cfbf8",
   "metadata": {},
   "source": [
    "### CaseHOLD labeling\n",
    "\n",
    "In this notebook, we run a labeling procedure on the test set of the CaseHOLD dataset. The dataset uses a \"citing prompt\", and contains five multiple choice answer options. We ask the LLM to read over the prompt and options, then select the best one.\n",
    "\n",
    "We test seven different LLMs, three from Amazon and four from Llama. We record the responses for each model for further analysis elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f474bd-1883-4f92-bbbb-0be96c39144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from boto3 import client\n",
    "from botocore.config import Config\n",
    "\n",
    "config = Config(read_timeout=1000)\n",
    "\n",
    "client = client(service_name='bedrock-runtime',\n",
    "                      config=config, region_name=\"us-east-1\")\n",
    "\n",
    "ds = load_dataset(\"casehold/casehold\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23205ca0-4420-4e4b-94c9-a818d97e58f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(r):\n",
    "    return \"\"\"Input: \"{}\"\n",
    "    Question: Consider the appropriate legal grammar and reasoning. Select which of the following clauses is the best replacement for the <HOLDING> tag above? \n",
    "    A: {}\n",
    "    B: {}\n",
    "    C: {}\n",
    "    D: {}\n",
    "    E: {}\n",
    "    \n",
    "    First think it through. Then provide your answer formatted in backticks like ANSWER:`A` or ANSWER:`C`.\n",
    "    \n",
    "    REASONING: \"\"\".format(r['citing_prompt'], r['holding_0'], r['holding_1'], r['holding_2'], r['holding_3'], r['holding_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc01b6-46a5-4042-9211-67599002349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ds['test'].to_pandas()\n",
    "test['label'] = test['label'].astype(float)\n",
    "test['final_prompt'] = test.apply(create_prompt, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b7a192-78c9-46a4-a0d9-d6b57741eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test['response_nova_micro'] = ''\n",
    "#test['response_nova_lite'] = ''\n",
    "#test['response_nova_pro'] = ''\n",
    "#test['response_llama_1b'] = ''\n",
    "#test['response_llama_3b'] = ''\n",
    "#test['response_llama_11b'] = ''\n",
    "#test['response_llama_90b'] = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d2bd66-9575-496d-b3ab-9218795b591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_nova_micro = ChatBedrockConverse(model=\"amazon.nova-micro-v1:0\", region_name=\"us-east-1\", temperature = 0, client = client)\n",
    "llm_nova_lite = ChatBedrockConverse(model=\"amazon.nova-lite-v1:0\", region_name=\"us-east-1\", temperature = 0, client = client)\n",
    "llm_nova_pro = ChatBedrockConverse(model=\"amazon.nova-pro-v1:0\", region_name=\"us-east-1\", temperature = 0, client = client)\n",
    "\n",
    "llm_llama32_1b = ChatBedrockConverse(model=\"us.meta.llama3-2-1b-instruct-v1:0\", region_name=\"us-east-1\", temperature = 0, client = client)\n",
    "llm_llama32_3b = ChatBedrockConverse(model=\"us.meta.llama3-2-3b-instruct-v1:0\", region_name=\"us-east-1\", temperature = 0, client = client)\n",
    "llm_llama32_11b = ChatBedrockConverse(model=\"us.meta.llama3-2-11b-instruct-v1:0\", region_name=\"us-east-1\", temperature = 0, client = client)\n",
    "llm_llama32_90b = ChatBedrockConverse(model=\"us.meta.llama3-2-90b-instruct-v1:0\", region_name=\"us-east-1\", temperature = 0, client = client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7d886a-0524-4c74-b917-dc7cabbfee75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, test.shape[0]):\n",
    "    \n",
    "    print(i)\n",
    "    row = test.loc[i]\n",
    "    messages = [\n",
    "        (\"user\", row['final_prompt'])\n",
    "    ]\n",
    "\n",
    "    a = llm_nova_micro.invoke(messages)\n",
    "    test.loc[i, 'response_nova_micro'] = a.content\n",
    "    \n",
    "    b = llm_nova_lite.invoke(messages)\n",
    "    test.loc[i, 'response_nova_lite'] = b.content\n",
    "\n",
    "    c = llm_nova_pro.invoke(messages)\n",
    "    test.loc[i, 'response_nova_pro'] = c.content\n",
    "\n",
    "    d = llm_llama32_1b.invoke(messages)\n",
    "    test.loc[i, 'response_llama_1b'] = d.content\n",
    "\n",
    "    e = llm_llama32_3b.invoke(messages)\n",
    "    test.loc[i, 'response_llama_3b'] = e.content\n",
    "\n",
    "    f = llm_llama32_11b.invoke(messages)\n",
    "    test.loc[i, 'response_llama_11b'] = f.content\n",
    "\n",
    "    g = llm_llama32_90b.invoke(messages)\n",
    "    test.loc[i, 'response_llama_90b'] = g.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99921c0f-b301-4bb1-9d99-f6902bea2c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('casehold_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scdb",
   "language": "python",
   "name": "scdb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
